{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark trials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNfSsArgvhxaOvrRIPCpzf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darkprogrammerpb/Python_trainings/blob/master/pyspark_trials_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4erquCTI3gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########## Run this code snippet when running for the first time and don't repeat it in future (else it will keep on downloading the same stuffs again and again and\n",
        "########## result in redundant usage of memory)\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apachemirror.wuchna.com/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0kbsXsSj3jD",
        "colab_type": "text"
      },
      "source": [
        "Code to initialise the pyspark session and loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrgZO4faI6OR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "import numpy as np\n",
        "os.environ[\"JAVA_HOME\"]   = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"]  = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "findspark.init(\"spark-2.4.4-bin-hadoop2.7\")# SPARK_HOME\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as f\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.functions import PandasUDFType\n",
        "from pyspark.sql.types import *\n",
        "spark                      = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lop5tRojj82V",
        "colab_type": "text"
      },
      "source": [
        "Loading the data to pyspark dataframe. We are reading a csv file in form of a pyspark dataframe and printing the first 2 rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgC_Av7xKZ2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "a867b910-6cc5-4ed6-ff70-57555a16156f"
      },
      "source": [
        "path = '/content/sample_data.csv'\n",
        "df = spark.read.csv(path,header=True,inferSchema=True)\n",
        "df.show(2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001002|  Male|     No|         0| Graduate|           No|           5849|              0.0|      null|             360|             1|        Urban|          Y|\n",
            "|LP001003|  Male|    Yes|         1| Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR-Gf7ibkIX7",
        "colab_type": "text"
      },
      "source": [
        "**Filtering a dataframe:-** We will filter the dataframe on basis of gender. We can pick single as well as multiple column as filters as shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpr6u4nDK1cI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8425e964-2003-419f-a8f4-4fa3af0a72a4"
      },
      "source": [
        "######## Filter a data frame based on just one condition #####################\n",
        "\n",
        "df1 = df.filter(df['Gender']=='Male')\n",
        "df2 = df.filter(df['Gender']=='Female')\n",
        "df1.show(2)\n",
        "df2.show(2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001002|  Male|     No|         0| Graduate|           No|           5849|              0.0|      null|             360|             1|        Urban|          Y|\n",
            "|LP001003|  Male|    Yes|         1| Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 2 rows\n",
            "\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001036|Female|     No|         0| Graduate|           No|           3510|              0.0|        76|             360|             0|        Urban|          N|\n",
            "|LP001087|Female|     No|         2| Graduate|         null|           3750|           2083.0|       120|             360|             1|    Semiurban|          Y|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljLnj1uZlGNW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "32551d17-80b4-456e-cfc6-a9983de4c0fb"
      },
      "source": [
        "######## Here we do filtering based on multiple columns\n",
        "df3 = df.filter((df['Gender']=='Male') & (df['Dependents']>0))\n",
        "df3.show(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001003|  Male|    Yes|         1| Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
            "|LP001011|  Male|    Yes|         2| Graduate|          Yes|           5417|           4196.0|       267|             360|             1|        Urban|          Y|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biYOF5j0lyoD",
        "colab_type": "text"
      },
      "source": [
        "**Describing a particular Column:-** We use describe functionality to describe a particular column of a dataframe. We can apply describe to multiple columns as well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BgFZLIgMKNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "e214c202-7b8d-4a49-c2d7-be56d65bf6be"
      },
      "source": [
        "######## Applying describe on a particular column\n",
        "df2.describe(['Loan_Amount_Term']).show()\n",
        "####### Applying describe on multiple columns\n",
        "df2.describe(['Loan_Amount_Term','Property_Area']).show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|  Loan_Amount_Term|\n",
            "+-------+------------------+\n",
            "|  count|               109|\n",
            "|   mean|352.29357798165137|\n",
            "| stddev| 56.72208119782669|\n",
            "|    min|                36|\n",
            "|    max|               480|\n",
            "+-------+------------------+\n",
            "\n",
            "+-------+------------------+-------------+\n",
            "|summary|  Loan_Amount_Term|Property_Area|\n",
            "+-------+------------------+-------------+\n",
            "|  count|               109|          112|\n",
            "|   mean|352.29357798165137|         null|\n",
            "| stddev| 56.72208119782669|         null|\n",
            "|    min|                36|        Rural|\n",
            "|    max|               480|        Urban|\n",
            "+-------+------------------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOhfklwtmo1o",
        "colab_type": "text"
      },
      "source": [
        "**Subsetting a dataframe based on some columns** Here we will be selecting only 5 columns of the dataframe and save them in another dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQRsFidm1SE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "a57f8157-2138-4463-cf48-c379066f0731"
      },
      "source": [
        "columns  = df.columns\n",
        "df4      = df.select(columns[1],columns[4],columns[0])\n",
        "df4.show(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---------+--------+\n",
            "|Gender|Education| Loan_ID|\n",
            "+------+---------+--------+\n",
            "|  Male| Graduate|LP001002|\n",
            "|  Male| Graduate|LP001003|\n",
            "|  Male| Graduate|LP001005|\n",
            "+------+---------+--------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMTYixnmOMw",
        "colab_type": "text"
      },
      "source": [
        "**Distinct Values in a column:-** We can use the distinct method to find distinct values in a particular dataframe column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukjtH3sFmYv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c41957d-7d94-46aa-9c3f-da66d32821b7"
      },
      "source": [
        "df.select('Education').distinct().count()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w95WkpUZo8pw",
        "colab_type": "text"
      },
      "source": [
        "**Dropping null values from a dataframe**:- We will drop null values from a dataframe using Dropna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KYUsZEDo73G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "1f3f862d-2a03-48dd-ecb2-923ea763f789"
      },
      "source": [
        "new_df = df.dropna(how='any')\n",
        "new_df.show(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001003|  Male|    Yes|         1| Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
            "|LP001005|  Male|    Yes|         0| Graduate|          Yes|           3000|              0.0|        66|             360|             1|        Urban|          Y|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3QUToISoFNv",
        "colab_type": "text"
      },
      "source": [
        "**GroupBy** We will by using groupby first using user defined functions first. We are taking Credit History as primary key for grouping and then applying aggregate functions accross the two columns mentioned- Dependents (max applied) and LoanAmount(average applied)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF_9V_OZoNEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f0e4b12c-20c8-4d0a-8b23-9871ef1fb6af"
      },
      "source": [
        "new_df.groupBy('Credit_History').agg({'Dependents':'max','LoanAmount':'avg'}).show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+------------------+---------------+\n",
            "|Credit_History|   avg(LoanAmount)|max(Dependents)|\n",
            "+--------------+------------------+---------------+\n",
            "|             1|143.38048780487804|             3+|\n",
            "|             0|152.67142857142858|             3+|\n",
            "+--------------+------------------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdG3DjXHoi1q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "0e366bab-4280-4a63-802c-c2e9226ae82a"
      },
      "source": [
        "### Applying a single function accross all the columns where it can be applied \n",
        "new_df.groupBy('Loan_Id').max().show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+--------------------+----------------------+---------------+---------------------+-------------------+\n",
            "| Loan_Id|max(ApplicantIncome)|max(CoapplicantIncome)|max(LoanAmount)|max(Loan_Amount_Term)|max(Credit_History)|\n",
            "+--------+--------------------+----------------------+---------------+---------------------+-------------------+\n",
            "|LP002448|                3948|                1733.0|            149|                  360|                  0|\n",
            "|LP002068|                4917|                   0.0|            130|                  360|                  0|\n",
            "|LP002537|                2083|                3150.0|            128|                  360|                  1|\n",
            "|LP001658|                3858|                   0.0|             76|                  360|                  1|\n",
            "|LP001940|                3153|                1560.0|            134|                  360|                  1|\n",
            "|LP002140|                8750|                4167.0|            308|                  360|                  1|\n",
            "|LP002692|                5677|                1424.0|            100|                  360|                  1|\n",
            "|LP001036|                3510|                   0.0|             76|                  360|                  0|\n",
            "|LP001194|                2708|                1167.0|             97|                  360|                  1|\n",
            "|LP001711|                3430|                1250.0|            128|                  360|                  0|\n",
            "|LP001532|                2281|                   0.0|            113|                  360|                  1|\n",
            "|LP002161|                4723|                   0.0|             81|                  360|                  1|\n",
            "|LP002958|                3676|                4301.0|            172|                  360|                  1|\n",
            "|LP001097|                4692|                   0.0|            106|                  360|                  1|\n",
            "|LP001206|                3029|                   0.0|             99|                  360|                  1|\n",
            "|LP002863|                6406|                   0.0|            150|                  360|                  1|\n",
            "|LP001924|                3158|                3053.0|             89|                  360|                  1|\n",
            "|LP002201|                9323|                7873.0|            380|                  300|                  1|\n",
            "|LP001144|                5821|                   0.0|            144|                  360|                  1|\n",
            "|LP002180|                6822|                   0.0|            141|                  360|                  1|\n",
            "+--------+--------------------+----------------------+---------------+---------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q8SPSq_8Odz",
        "colab_type": "text"
      },
      "source": [
        "**User Defined Functions in GroupBy:-** We will be using user defined functions in Groupby and hence we will introduce the concept of pandas UDF (user defined function). Here we are calculating the sum of all installments possible from the loan amount given in different Property areas (Urban, Rural and Semi Urban). The installment on one loan is attained by dividing the loan amount by loan term *(we are keeping things simple here and hence will just focus on a simple function for demonstration purpose.)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "si-Iqs-Zq5Is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "621e3621-963f-4dd9-e37f-ec402bc68343"
      },
      "source": [
        "@pandas_udf(FloatType(), functionType=PandasUDFType.GROUPED_AGG)\n",
        "def per_inst_amt(loan_amount,loan_term):\n",
        "  installments = loan_amount/loan_term\n",
        "  return installments.sum()\n",
        "  \n",
        "new_df.groupBy(\"Property_Area\").agg(per_inst_amt(\"LoanAmount\", \"Loan_Amount_Term\").alias(\"Installment_sums\")).show()  "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+----------------+\n",
            "|Property_Area|Installment_sums|\n",
            "+-------------+----------------+\n",
            "|        Urban|       65.167656|\n",
            "|    Semiurban|       89.924164|\n",
            "|        Rural|        65.35651|\n",
            "+-------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn9sY8IC9SDj",
        "colab_type": "text"
      },
      "source": [
        "**User defined Functions in Pyspark:-** We will create user defined functions here for the first time. It will take one(or more) columns as inputs and output a column.\n",
        "\n",
        "---\n",
        "Let us suppose we want to consider the monthly installment subject to each loan. and we provide an interest rate of 4% for Urban areas, 3% for semi urban areas and 2% for rural areas. We want to save the monthly installment in a new column -EMI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xny-e4yGrmxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_monthly_installment(loan_amount,loan_term,property_area):\n",
        "  if property_area =='Rural':\n",
        "    return float(np.ppmt(0.02/12,1,loan_term/12.0,-1*float(loan_amount)))\n",
        "  elif property_area == 'Semiurban':\n",
        "    return float(np.ppmt(0.03/12,1,loan_term/12.0,-1*float(loan_amount)))\n",
        "  else:\n",
        "    return float(np.ppmt(0.04/12,1,loan_term/12.0,-1*float(loan_amount)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YofHGVRe-_p8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "emi_udf = udf(calculate_monthly_installment, FloatType())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whCWj-Go_A0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emidf = new_df.withColumn(\"EMI\", emi_udf(new_df['LoanAmount'],new_df['Loan_Amount_Term'],new_df['Property_Area']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZttwV0_4-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "a01c1111-8caf-4733-b463-1890916e655f"
      },
      "source": [
        "emidf.select('Loan_ID','EMI','Loan_Amount_Term','LoanAmount','Property_Area').show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+----------+----------------+----------+-------------+\n",
            "| Loan_ID|       EMI|Loan_Amount_Term|LoanAmount|Property_Area|\n",
            "+--------+----------+----------------+----------+-------------+\n",
            "|LP001003| 4.1644425|             360|       128|        Rural|\n",
            "|LP001005| 2.0954945|             360|        66|        Urban|\n",
            "|LP001006| 3.8099902|             360|       120|        Urban|\n",
            "|LP001008| 4.4767385|             360|       141|        Urban|\n",
            "|LP001011|  8.477228|             360|       267|        Urban|\n",
            "|LP001013| 3.0162423|             360|        95|        Urban|\n",
            "|LP001014| 5.0782127|             360|       158|    Semiurban|\n",
            "|LP001018| 5.3339863|             360|       168|        Urban|\n",
            "|LP001020| 11.217065|             360|       349|    Semiurban|\n",
            "|LP001024| 2.2224944|             360|        70|        Urban|\n",
            "|LP001028| 6.3499837|             360|       200|        Urban|\n",
            "|LP001029| 3.7089567|             360|       114|        Rural|\n",
            "|LP001030| 1.6746556|             120|        17|        Urban|\n",
            "|LP001032| 3.9687397|             360|       125|        Urban|\n",
            "|LP001036|  2.412994|             360|        76|        Urban|\n",
            "|LP001038|  4.327116|             360|       133|        Rural|\n",
            "|LP001043| 3.3019915|             360|       104|        Urban|\n",
            "|LP001046|10.0012245|             360|       315|        Urban|\n",
            "|LP001047|  3.728308|             360|       116|    Semiurban|\n",
            "|LP001066|  6.138852|             360|       191|    Semiurban|\n",
            "+--------+----------+----------------+----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5GUxESSBYWJ",
        "colab_type": "text"
      },
      "source": [
        "**Joins in Pyspark Dataframe:-** We will create two datasets and perform joins on them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jbw2IeQN9YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import *\n",
        "Dataset1 = Row(\"primekey\", \"value1\", \"value2\")\n",
        "Dataset2 = Row(\"primekey\", \"value3\", \"value4\")\n",
        "data1   = [Dataset1('A', 12, 12),\n",
        "            Dataset1('A', 14,16),\n",
        "            Dataset1('B', 16,10),\n",
        "            Dataset1('c', 20,22),\n",
        "            Dataset1('c', 41,44)]\n",
        "data2   = [Dataset2('A', 12, 16),\n",
        "            Dataset2('B', 78,88),\n",
        "            Dataset2('B', 99,21),\n",
        "            Dataset2('D', 23,61),\n",
        "            Dataset2('E', 42,11)]\n",
        "df11 = spark.createDataFrame(data1)\n",
        "df22 = spark.createDataFrame(data2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yhKB6IfCS6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df5 = df11.join(df22, on=['primekey'],how='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mr5yyw2ChFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f160d1bd-a248-4018-90ee-7f2595ecb0ae"
      },
      "source": [
        "df5.show(5)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+------+------+------+\n",
            "|primekey|value1|value2|value3|value4|\n",
            "+--------+------+------+------+------+\n",
            "|       B|    16|    10|    78|    88|\n",
            "|       B|    16|    10|    99|    21|\n",
            "|       A|    12|    12|    12|    16|\n",
            "|       A|    14|    16|    12|    16|\n",
            "+--------+------+------+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dlw1J_HDjAK",
        "colab_type": "text"
      },
      "source": [
        "**Note(very important while performing Joins) :-** Always perform joins in the above syntax. There may be ways to join a dataframe using some specific methods as mentioned online but they all may suffer from a very subtle issue which causes errors while performing computations in future. Let me demonstrate via example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjtHOzHODV0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "dc8b615b-abc0-4dab-8ea1-d5ff23b74852"
      },
      "source": [
        "df5_1 = df11.join(df22, df11['primekey']==df22['primekey'])\n",
        "df5_1.show()\n",
        "print('The number of times the column -primekey appears using our current joining appreach is :- ',df5_1.columns.count('primekey'))\n",
        "print('The number of times the column -primekey appeared in our previous joining approach is  :- ',df5.columns.count('primekey'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+------+--------+------+------+\n",
            "|primekey|value1|value2|primekey|value3|value4|\n",
            "+--------+------+------+--------+------+------+\n",
            "|       B|    16|    10|       B|    78|    88|\n",
            "|       B|    16|    10|       B|    99|    21|\n",
            "|       A|    12|    12|       A|    12|    16|\n",
            "|       A|    14|    16|       A|    12|    16|\n",
            "+--------+------+------+--------+------+------+\n",
            "\n",
            "The number of times the column -primekey appears using our current joining appreach is :-  2\n",
            "The number of times the column -primekey appeared in our previous joining approach is  :-  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWJZjquoEkjE",
        "colab_type": "text"
      },
      "source": [
        "We can clearly see that the current joining caused duplication of the column Education on which the join was made and hence it must be avoided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_0dMtBmGGBD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "964b6e67-8354-4bda-f2f7-6642750fa037"
      },
      "source": [
        "### Sample demonstration of right join\n",
        "df6 = df11.join(df22,on=['primekey'],how='right').show()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+------+------+------+\n",
            "|primekey|value1|value2|value3|value4|\n",
            "+--------+------+------+------+------+\n",
            "|       E|  null|  null|    42|    11|\n",
            "|       B|    16|    10|    78|    88|\n",
            "|       B|    16|    10|    99|    21|\n",
            "|       D|  null|  null|    23|    61|\n",
            "|       A|    12|    12|    12|    16|\n",
            "|       A|    14|    16|    12|    16|\n",
            "+--------+------+------+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-bh7qRTQZu9",
        "colab_type": "text"
      },
      "source": [
        "**Union:-** Appending one dataframe at the end of other using union function. We will use union to append df1 and df2 (created previously) together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAm77GRBQP75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "uniondf = df1.union(df2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRdNTfHTQrPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "13cfec0c-bb0d-40f9-fd9a-8521db33b336"
      },
      "source": [
        "uniondf.show(3)\n",
        "print('length of df1:- ',df1.count())\n",
        "print('length of df2:- ',df2.count())\n",
        "print('length of appended df:- ',uniondf.count())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "| Loan_ID|Gender|Married|Dependents|Education|Self_Employed|ApplicantIncome|CoapplicantIncome|LoanAmount|Loan_Amount_Term|Credit_History|Property_Area|Loan_Status|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "|LP001002|  Male|     No|         0| Graduate|           No|           5849|              0.0|      null|             360|             1|        Urban|          Y|\n",
            "|LP001003|  Male|    Yes|         1| Graduate|           No|           4583|           1508.0|       128|             360|             1|        Rural|          N|\n",
            "|LP001005|  Male|    Yes|         0| Graduate|          Yes|           3000|              0.0|        66|             360|             1|        Urban|          Y|\n",
            "+--------+------+-------+----------+---------+-------------+---------------+-----------------+----------+----------------+--------------+-------------+-----------+\n",
            "only showing top 3 rows\n",
            "\n",
            "length of df1:-  489\n",
            "length of df2:-  112\n",
            "length of appended df:-  601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY70rn4KQvxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}